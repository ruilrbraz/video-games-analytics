{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae9e73c-b4ed-4b80-bb2e-9bd52ee94e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from 'Video_Games.csv'...\n",
      "Cleaning data (from 2.2_cleaning_and_data_manipulation.ipynb)...\n",
      "Creating 'Developers' dimension...\n",
      "Creating 'Publishers' dimension...\n",
      "Mapping foreign keys using pd.merge()...\n",
      "Preparing final 'Games' table...\n",
      "Exporting clean data to CSV files...\n",
      "\n",
      "--- Data Transformation and Export Complete! ---\n",
      "You now have three clean CSV files ready for database import:\n",
      "1. developers.csv\n",
      "2. publishers.csv\n",
      "3. games_final.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- Configuration ---\n",
    "RAW_CSV_FILE = 'Video_Games.csv'\n",
    "\n",
    "# --- Output Files ---\n",
    "PUBLISHERS_CSV = 'publishers.csv'\n",
    "DEVELOPERS_CSV = 'developers.csv'\n",
    "GAMES_CSV = 'games_final.csv'\n",
    "\n",
    "def transform_and_export():\n",
    "    \"\"\"\n",
    "    Reads the raw CSV, cleans it using only Pandas, and exports\n",
    "    three separate, relational CSVs ready for database import.\n",
    "    This script does NOT require sqlalchemy or sqlite3.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # --- Step 1: Read and Clean CSV Data (from 2.1 & 2.2) ---\n",
    "        print(f\"Reading data from '{RAW_CSV_FILE}'...\")\n",
    "        df = pd.read_csv(RAW_CSV_FILE, index_col=0) # From 2.1_pandas.ipynb\n",
    "\n",
    "        print(\"Cleaning data (from 2.2_cleaning_and_data_manipulation.ipynb)...\")\n",
    "        \n",
    "        # A. Clean User_Score: Replace 'tbd' with NaN (NULL)\n",
    "        # We saw .replace() in 2.2_cleaning_and_data_manipulation.ipynb\n",
    "        df['User_Score'] = df['User_Score'].replace('tbd', np.nan)\n",
    "        df['User_Score'] = pd.to_numeric(df['User_Score'], errors='coerce')\n",
    "        \n",
    "        # B. Clean Year_of_Release: Convert float (e.g., 2006.0) to a nullable integer\n",
    "        df['Year_of_Release'] = df['Year_of_Release'].astype('Int64')\n",
    "\n",
    "        # C. Handle missing relational data: Fill NaN in Developer/Publisher\n",
    "        # We saw .fillna() in 2.2_cleaning_and_data_manipulation.ipynb\n",
    "        df['Developer'] = df['Developer'].fillna('Unknown')\n",
    "        df['Publisher'] = df['Publisher'].fillna('Unknown')\n",
    "        \n",
    "        # --- Step 2: Extract and Create Dimension DataFrames (from 2.1) ---\n",
    "        print(\"Creating 'Developers' dimension...\")\n",
    "        # Get unique developer names (from 2.2_cleaning_and_data_manipulation.ipynb)\n",
    "        unique_developers = pd.DataFrame(df['Developer'].unique(), columns=['developer_name'])\n",
    "        # Add the 'developer_id' which matches our SQL schema\n",
    "        unique_developers.insert(0, 'developer_id', unique_developers.index + 1)\n",
    "        \n",
    "        print(\"Creating 'Publishers' dimension...\")\n",
    "        # Get unique publisher names\n",
    "        unique_publishers = pd.DataFrame(df['Publisher'].unique(), columns=['publisher_name'])\n",
    "        # Add the 'publisher_id'\n",
    "        unique_publishers.insert(0, 'publisher_id', unique_publishers.index + 1)\n",
    "\n",
    "        # --- Step 3: Map Foreign Keys (from 2.3_combining_structuring_data.ipynb) ---\n",
    "        print(\"Mapping foreign keys using pd.merge()...\")\n",
    "        \n",
    "        # Use pd.merge() to add the new IDs back to the main DataFrame\n",
    "        # This is just like the 'merge' examples in 2.3_combining_structuring_data.ipynb\n",
    "        df = pd.merge(df, unique_developers, left_on='Developer', right_on='developer_name', how='left')\n",
    "        df = pd.merge(df, unique_publishers, left_on='Publisher', right_on='publisher_name', how='left')\n",
    "\n",
    "        # --- Step 4: Prepare and Export Final CSVs ---\n",
    "        print(\"Preparing final 'Games' table...\")\n",
    "        \n",
    "        # Rename columns to match the SQL schema exactly\n",
    "        df = df.rename(columns={\n",
    "            'Name': 'game_name',\n",
    "            'Platform': 'platform',\n",
    "            'Year_of_Release': 'year_of_release',\n",
    "            'Genre': 'genre',\n",
    "            'NA_Sales': 'na_sales',\n",
    "            'EU_Sales': 'eu_sales',\n",
    "            'JP_Sales': 'jp_sales',\n",
    "            'Other_Sales': 'other_sales',\n",
    "            'Global_Sales': 'global_sales',\n",
    "            'Critic_Score': 'critic_score',\n",
    "            'Critic_Count': 'critic_count',\n",
    "            'User_Score': 'user_score',\n",
    "            'User_Count': 'user_count',\n",
    "            'Rating': 'rating',\n",
    "            'publisher_id': 'fk_publisher_id', # This is from the merge\n",
    "            'developer_id': 'fk_developer_id'  # This is from the merge\n",
    "        })\n",
    "        \n",
    "        # Select *only* the columns that exist in the 'Games' table schema\n",
    "        final_games_columns = [\n",
    "            'game_name', 'platform', 'year_of_release', 'genre', 'na_sales',\n",
    "            'eu_sales', 'jp_sales', 'other_sales', 'global_sales',\n",
    "            'critic_score', 'critic_count', 'user_score', 'user_count',\n",
    "            'rating', 'fk_publisher_id', 'fk_developer_id'\n",
    "        ]\n",
    "        \n",
    "        df_games_final = df[final_games_columns]\n",
    "\n",
    "        # --- Step 5: Export all three CSVs ---\n",
    "        print(f\"Exporting clean data to CSV files...\")\n",
    "        \n",
    "        # Export the dimension tables\n",
    "        unique_developers.to_csv(DEVELOPERS_CSV, index=False)\n",
    "        unique_publishers.to_csv(PUBLISHERS_CSV, index=False)\n",
    "        \n",
    "        # Export the final fact table\n",
    "        df_games_final.to_csv(GAMES_CSV, index=False)\n",
    "        \n",
    "        print(\"\\n--- Data Transformation and Export Complete! ---\")\n",
    "        print(\"You now have three clean CSV files ready for database import:\")\n",
    "        print(f\"1. {DEVELOPERS_CSV}\")\n",
    "        print(f\"2. {PUBLISHERS_CSV}\")\n",
    "        print(f\"3. {GAMES_CSV}\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Could not find file. Make sure '{e.filename}' is in the same folder.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# --- Main execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    transform_and_export()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54e83fa-c9d0-4794-8af0-25e8b5e30ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
